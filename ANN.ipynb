{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = pd.read_csv(\"adult.csv\")\n",
    "ds.replace('?', np.nan, inplace=True)\n",
    "ds.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=ds.iloc[:,:-1].values\n",
    "y=ds.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer \n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy=\"most_frequent\")\n",
    "x_train[:, 1:]=imputer.fit_transform(x_train[:,1:]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "ordinal_categorical_columns = [1, 3, 5, 6, 7, 8, 9, 13]\n",
    "\n",
    "label_encoders = []\n",
    "for col_index in ordinal_categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    x_train[:, col_index] = le.fit_transform(x_train[:, col_index])\n",
    "    x_test[:, col_index] = le.transform(x_test[:, col_index])\n",
    "    label_encoders.append(le)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "lb_obj= LabelEncoder() \n",
    "y_train=lb_obj.fit_transform(y_train)\n",
    "y_test=lb_obj.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler() \n",
    "x_train_StandardScaled = scaler.fit_transform(x_train)\n",
    "x_test_StandardScaled = scaler.transform(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_model=tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_model.add(tf.keras.layers.Dense(units=8,activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_model.add(tf.keras.layers.Dense(units=8,activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_model.add(tf.keras.layers.Dense(units=1,activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),loss=\"binary_crossentropy\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "755/755 [==============================] - 3s 2ms/step - loss: 0.5383 - accuracy: 0.7327\n",
      "Epoch 2/100\n",
      "755/755 [==============================] - 1s 2ms/step - loss: 0.3748 - accuracy: 0.8278\n",
      "Epoch 3/100\n",
      "755/755 [==============================] - 1s 2ms/step - loss: 0.3515 - accuracy: 0.8364\n",
      "Epoch 4/100\n",
      "755/755 [==============================] - 1s 2ms/step - loss: 0.3410 - accuracy: 0.8405\n",
      "Epoch 5/100\n",
      "755/755 [==============================] - 2s 2ms/step - loss: 0.3355 - accuracy: 0.8431\n",
      "Epoch 6/100\n",
      "755/755 [==============================] - 1s 2ms/step - loss: 0.3323 - accuracy: 0.8439\n",
      "Epoch 7/100\n",
      "755/755 [==============================] - 1s 2ms/step - loss: 0.3306 - accuracy: 0.8436\n",
      "Epoch 8/100\n",
      "755/755 [==============================] - 1s 2ms/step - loss: 0.3295 - accuracy: 0.8440\n",
      "Epoch 9/100\n",
      "755/755 [==============================] - 1s 2ms/step - loss: 0.3286 - accuracy: 0.8449\n",
      "Epoch 10/100\n",
      "755/755 [==============================] - 1s 2ms/step - loss: 0.3279 - accuracy: 0.8451\n",
      "Epoch 11/100\n",
      "755/755 [==============================] - 1s 2ms/step - loss: 0.3270 - accuracy: 0.8452\n",
      "Epoch 12/100\n",
      "755/755 [==============================] - 1s 2ms/step - loss: 0.3265 - accuracy: 0.8454\n",
      "Epoch 13/100\n",
      "755/755 [==============================] - 1s 2ms/step - loss: 0.3263 - accuracy: 0.8455\n",
      "Epoch 14/100\n",
      "755/755 [==============================] - 1s 2ms/step - loss: 0.3260 - accuracy: 0.8462\n",
      "Epoch 15/100\n",
      "755/755 [==============================] - 1s 2ms/step - loss: 0.3254 - accuracy: 0.8478\n",
      "Epoch 16/100\n",
      "755/755 [==============================] - 1s 2ms/step - loss: 0.3253 - accuracy: 0.8473\n",
      "Epoch 17/100\n",
      "755/755 [==============================] - 2s 2ms/step - loss: 0.3252 - accuracy: 0.8472\n",
      "Epoch 18/100\n",
      "755/755 [==============================] - 1s 2ms/step - loss: 0.3248 - accuracy: 0.8467\n",
      "Epoch 19/100\n",
      "755/755 [==============================] - 1s 2ms/step - loss: 0.3245 - accuracy: 0.8466\n",
      "Epoch 20/100\n",
      "755/755 [==============================] - 1s 2ms/step - loss: 0.3248 - accuracy: 0.8476\n",
      "Epoch 21/100\n",
      "755/755 [==============================] - 1s 2ms/step - loss: 0.3242 - accuracy: 0.8474\n",
      "Epoch 22/100\n",
      "755/755 [==============================] - 1s 2ms/step - loss: 0.3243 - accuracy: 0.8479\n",
      "Epoch 23/100\n",
      "755/755 [==============================] - 1s 2ms/step - loss: 0.3242 - accuracy: 0.8473\n",
      "Epoch 24/100\n",
      "755/755 [==============================] - 1s 2ms/step - loss: 0.3240 - accuracy: 0.8475\n",
      "Epoch 25/100\n",
      "755/755 [==============================] - 1s 2ms/step - loss: 0.3238 - accuracy: 0.8479\n",
      "Epoch 26/100\n",
      "755/755 [==============================] - 1s 2ms/step - loss: 0.3237 - accuracy: 0.8484\n",
      "Epoch 27/100\n",
      "755/755 [==============================] - 1s 2ms/step - loss: 0.3237 - accuracy: 0.8473\n",
      "Epoch 28/100\n",
      "755/755 [==============================] - 1s 2ms/step - loss: 0.3235 - accuracy: 0.8471\n",
      "Epoch 29/100\n",
      "755/755 [==============================] - 1s 2ms/step - loss: 0.3236 - accuracy: 0.8473\n",
      "Epoch 30/100\n",
      "755/755 [==============================] - 1s 2ms/step - loss: 0.3231 - accuracy: 0.8480\n",
      "Epoch 31/100\n",
      "755/755 [==============================] - 1s 2ms/step - loss: 0.3232 - accuracy: 0.8477\n",
      "Epoch 32/100\n",
      "755/755 [==============================] - 1s 2ms/step - loss: 0.3230 - accuracy: 0.8471\n",
      "Epoch 33/100\n",
      "755/755 [==============================] - 1s 2ms/step - loss: 0.3228 - accuracy: 0.8475\n",
      "Epoch 34/100\n",
      "755/755 [==============================] - 1s 2ms/step - loss: 0.3227 - accuracy: 0.8479\n",
      "Epoch 35/100\n",
      "755/755 [==============================] - 1s 2ms/step - loss: 0.3227 - accuracy: 0.8476\n",
      "Epoch 36/100\n",
      "755/755 [==============================] - 1s 2ms/step - loss: 0.3227 - accuracy: 0.8467\n",
      "Epoch 37/100\n",
      "755/755 [==============================] - 1s 2ms/step - loss: 0.3225 - accuracy: 0.8481\n",
      "Epoch 38/100\n",
      "755/755 [==============================] - 1s 2ms/step - loss: 0.3225 - accuracy: 0.8485\n",
      "Epoch 39/100\n",
      "755/755 [==============================] - 2s 2ms/step - loss: 0.3226 - accuracy: 0.8481\n",
      "Epoch 40/100\n",
      "755/755 [==============================] - 1s 2ms/step - loss: 0.3224 - accuracy: 0.8479\n",
      "Epoch 41/100\n",
      "755/755 [==============================] - 2s 2ms/step - loss: 0.3224 - accuracy: 0.8477\n",
      "Epoch 42/100\n",
      "755/755 [==============================] - 2s 2ms/step - loss: 0.3228 - accuracy: 0.8465\n",
      "Epoch 43/100\n",
      "755/755 [==============================] - 2s 2ms/step - loss: 0.3221 - accuracy: 0.8485\n",
      "Epoch 44/100\n",
      "755/755 [==============================] - 2s 2ms/step - loss: 0.3222 - accuracy: 0.8473\n",
      "Epoch 45/100\n",
      "755/755 [==============================] - 1s 2ms/step - loss: 0.3221 - accuracy: 0.8478\n",
      "Epoch 46/100\n",
      "755/755 [==============================] - 2s 2ms/step - loss: 0.3220 - accuracy: 0.8480\n",
      "Epoch 47/100\n",
      "755/755 [==============================] - 2s 2ms/step - loss: 0.3220 - accuracy: 0.8473\n",
      "Epoch 48/100\n",
      "755/755 [==============================] - 1s 2ms/step - loss: 0.3221 - accuracy: 0.8467\n",
      "Epoch 49/100\n",
      "755/755 [==============================] - 1s 2ms/step - loss: 0.3218 - accuracy: 0.8472\n",
      "Epoch 50/100\n",
      "755/755 [==============================] - 1s 2ms/step - loss: 0.3220 - accuracy: 0.8477\n",
      "Epoch 51/100\n",
      "755/755 [==============================] - 1s 2ms/step - loss: 0.3216 - accuracy: 0.8481\n",
      "Epoch 52/100\n",
      "755/755 [==============================] - 1s 2ms/step - loss: 0.3218 - accuracy: 0.8478\n",
      "Epoch 53/100\n",
      "755/755 [==============================] - 1s 2ms/step - loss: 0.3216 - accuracy: 0.8478\n",
      "Epoch 54/100\n",
      "755/755 [==============================] - 2s 2ms/step - loss: 0.3218 - accuracy: 0.8469\n",
      "Epoch 55/100\n",
      "755/755 [==============================] - 2s 3ms/step - loss: 0.3215 - accuracy: 0.8471\n",
      "Epoch 56/100\n",
      "755/755 [==============================] - 2s 3ms/step - loss: 0.3214 - accuracy: 0.8481\n",
      "Epoch 57/100\n",
      "755/755 [==============================] - 2s 2ms/step - loss: 0.3213 - accuracy: 0.8473\n",
      "Epoch 58/100\n",
      "755/755 [==============================] - 2s 2ms/step - loss: 0.3213 - accuracy: 0.8485\n",
      "Epoch 59/100\n",
      "755/755 [==============================] - 2s 2ms/step - loss: 0.3215 - accuracy: 0.8482\n",
      "Epoch 60/100\n",
      "755/755 [==============================] - 2s 2ms/step - loss: 0.3212 - accuracy: 0.8479\n",
      "Epoch 61/100\n",
      "755/755 [==============================] - 2s 2ms/step - loss: 0.3213 - accuracy: 0.8467\n",
      "Epoch 62/100\n",
      "755/755 [==============================] - 2s 2ms/step - loss: 0.3215 - accuracy: 0.8484\n",
      "Epoch 63/100\n",
      "755/755 [==============================] - 2s 2ms/step - loss: 0.3216 - accuracy: 0.8479\n",
      "Epoch 64/100\n",
      "755/755 [==============================] - 2s 2ms/step - loss: 0.3209 - accuracy: 0.8479\n",
      "Epoch 65/100\n",
      "755/755 [==============================] - 2s 2ms/step - loss: 0.3211 - accuracy: 0.8482\n",
      "Epoch 66/100\n",
      "755/755 [==============================] - 1s 2ms/step - loss: 0.3209 - accuracy: 0.8494\n",
      "Epoch 67/100\n",
      "755/755 [==============================] - 1s 2ms/step - loss: 0.3214 - accuracy: 0.8481\n",
      "Epoch 68/100\n",
      "755/755 [==============================] - 2s 2ms/step - loss: 0.3207 - accuracy: 0.8480\n",
      "Epoch 69/100\n",
      "755/755 [==============================] - 2s 2ms/step - loss: 0.3211 - accuracy: 0.8484\n",
      "Epoch 70/100\n",
      "755/755 [==============================] - 1s 2ms/step - loss: 0.3209 - accuracy: 0.8489\n",
      "Epoch 71/100\n",
      "755/755 [==============================] - 2s 2ms/step - loss: 0.3208 - accuracy: 0.8482\n",
      "Epoch 72/100\n",
      "755/755 [==============================] - 1s 2ms/step - loss: 0.3209 - accuracy: 0.8486\n",
      "Epoch 73/100\n",
      "755/755 [==============================] - 2s 2ms/step - loss: 0.3209 - accuracy: 0.8488\n",
      "Epoch 74/100\n",
      "755/755 [==============================] - 1s 2ms/step - loss: 0.3209 - accuracy: 0.8490\n",
      "Epoch 75/100\n",
      "755/755 [==============================] - 1s 2ms/step - loss: 0.3206 - accuracy: 0.8481\n",
      "Epoch 76/100\n",
      "755/755 [==============================] - 2s 2ms/step - loss: 0.3208 - accuracy: 0.8484\n",
      "Epoch 77/100\n",
      "755/755 [==============================] - 1s 2ms/step - loss: 0.3208 - accuracy: 0.8485\n",
      "Epoch 78/100\n",
      "755/755 [==============================] - 1s 2ms/step - loss: 0.3204 - accuracy: 0.8483\n",
      "Epoch 79/100\n",
      "755/755 [==============================] - 2s 2ms/step - loss: 0.3205 - accuracy: 0.8489\n",
      "Epoch 80/100\n",
      "755/755 [==============================] - 2s 2ms/step - loss: 0.3208 - accuracy: 0.8474\n",
      "Epoch 81/100\n",
      "755/755 [==============================] - 1s 2ms/step - loss: 0.3204 - accuracy: 0.8490\n",
      "Epoch 82/100\n",
      "755/755 [==============================] - 2s 2ms/step - loss: 0.3204 - accuracy: 0.8491\n",
      "Epoch 83/100\n",
      "755/755 [==============================] - 2s 2ms/step - loss: 0.3206 - accuracy: 0.8476\n",
      "Epoch 84/100\n",
      "755/755 [==============================] - 2s 2ms/step - loss: 0.3203 - accuracy: 0.8490\n",
      "Epoch 85/100\n",
      "755/755 [==============================] - 2s 2ms/step - loss: 0.3203 - accuracy: 0.8494\n",
      "Epoch 86/100\n",
      "755/755 [==============================] - 1s 2ms/step - loss: 0.3204 - accuracy: 0.8481\n",
      "Epoch 87/100\n",
      "755/755 [==============================] - 2s 2ms/step - loss: 0.3203 - accuracy: 0.8491\n",
      "Epoch 88/100\n",
      "755/755 [==============================] - 2s 2ms/step - loss: 0.3203 - accuracy: 0.8474\n",
      "Epoch 89/100\n",
      "755/755 [==============================] - 2s 2ms/step - loss: 0.3205 - accuracy: 0.8488\n",
      "Epoch 90/100\n",
      "755/755 [==============================] - 2s 2ms/step - loss: 0.3201 - accuracy: 0.8486\n",
      "Epoch 91/100\n",
      "755/755 [==============================] - 1s 2ms/step - loss: 0.3202 - accuracy: 0.8481\n",
      "Epoch 92/100\n",
      "755/755 [==============================] - 2s 2ms/step - loss: 0.3201 - accuracy: 0.8482\n",
      "Epoch 93/100\n",
      "755/755 [==============================] - 1s 2ms/step - loss: 0.3204 - accuracy: 0.8479\n",
      "Epoch 94/100\n",
      "755/755 [==============================] - 1s 2ms/step - loss: 0.3199 - accuracy: 0.8489\n",
      "Epoch 95/100\n",
      "755/755 [==============================] - 2s 2ms/step - loss: 0.3204 - accuracy: 0.8498\n",
      "Epoch 96/100\n",
      "755/755 [==============================] - 2s 2ms/step - loss: 0.3198 - accuracy: 0.8482\n",
      "Epoch 97/100\n",
      "755/755 [==============================] - 2s 2ms/step - loss: 0.3202 - accuracy: 0.8483\n",
      "Epoch 98/100\n",
      "755/755 [==============================] - 2s 2ms/step - loss: 0.3202 - accuracy: 0.8490\n",
      "Epoch 99/100\n",
      "755/755 [==============================] - 2s 2ms/step - loss: 0.3200 - accuracy: 0.8491\n",
      "Epoch 100/100\n",
      "755/755 [==============================] - 2s 2ms/step - loss: 0.3200 - accuracy: 0.8470\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1e71479ad30>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_model.fit(x_train_StandardScaled,y_train,batch_size=32,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 8)                 120       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 72        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 201 (804.00 Byte)\n",
      "Trainable params: 201 (804.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ann_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 185ms/step\n",
      "[[False]]\n"
     ]
    }
   ],
   "source": [
    "print(ann_model.predict(scaler.transform([[0.177807, 0.088108,0.173244,1.218035,-0.036491,-0.407250,1.289114,-0.898177,0.394225,0.698654,-0.144749,-0.21852,0.851632,0.292299]]))> 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189/189 [==============================] - 0s 2ms/step\n",
      "[[1 1]\n",
      " [1 0]\n",
      " [0 0]\n",
      " ...\n",
      " [0 0]\n",
      " [1 0]\n",
      " [1 0]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = ann_model.predict(x_test_StandardScaled)\n",
    "y_pred = (y_pred > 0.5)\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8461793469252444"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 00m 22s]\n",
      "val_accuracy: 0.8452134132385254\n",
      "\n",
      "Best val_accuracy So Far: 0.8452134132385254\n",
      "Total elapsed time: 00h 04m 24s\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 12)                180       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 20)                260       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 461 (1.80 KB)\n",
      "Trainable params: 461 (1.80 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "189/189 [==============================] - 1s 2ms/step - loss: 0.3369 - accuracy: 0.8455\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3368646204471588, 0.8455163240432739]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import callbacks\n",
    "from kerastuner.tuners import RandomSearch\n",
    "\n",
    "\n",
    "\n",
    "# Define the model building function\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=hp.Int('units_1', min_value=4, max_value=64, step=4), activation='relu', input_shape=(x_train.shape[1],)))\n",
    "    model.add(Dense(units=hp.Int('units_2', min_value=4, max_value=64, step=4), activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Instantiate the tuner\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=5,  # Adjust the number of trials based on computational resources\n",
    "    executions_per_trial=1,\n",
    "    directory='ann_tuning',\n",
    "    project_name='adult_dataset'\n",
    ")\n",
    "\n",
    "# Callback to stop training early if val_loss doesn't improve after a certain number of epochs\n",
    "early_stop = callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "# Perform the hyperparameter search\n",
    "tuner.search(x_train_StandardScaled, y_train, epochs=50, validation_split=0.2, callbacks=[early_stop])\n",
    "\n",
    "# Get the best model and print the summary\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "best_model.summary()\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "best_model.evaluate(x_test_StandardScaled, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "679/679 [==============================] - 5s 4ms/step - loss: 0.4954 - accuracy: 0.7646 - val_loss: 0.3915 - val_accuracy: 0.8152\n",
      "Epoch 2/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3766 - accuracy: 0.8240 - val_loss: 0.3603 - val_accuracy: 0.8251\n",
      "Epoch 3/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3554 - accuracy: 0.8329 - val_loss: 0.3502 - val_accuracy: 0.8322\n",
      "Epoch 4/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3460 - accuracy: 0.8354 - val_loss: 0.3450 - val_accuracy: 0.8309\n",
      "Epoch 5/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3408 - accuracy: 0.8401 - val_loss: 0.3441 - val_accuracy: 0.8367\n",
      "Epoch 6/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3378 - accuracy: 0.8413 - val_loss: 0.3408 - val_accuracy: 0.8334\n",
      "Epoch 7/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3361 - accuracy: 0.8407 - val_loss: 0.3397 - val_accuracy: 0.8338\n",
      "Epoch 8/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3351 - accuracy: 0.8420 - val_loss: 0.3386 - val_accuracy: 0.8334\n",
      "Epoch 9/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3337 - accuracy: 0.8427 - val_loss: 0.3392 - val_accuracy: 0.8380\n",
      "Epoch 10/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3328 - accuracy: 0.8434 - val_loss: 0.3395 - val_accuracy: 0.8384\n",
      "Epoch 11/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3320 - accuracy: 0.8448 - val_loss: 0.3395 - val_accuracy: 0.8367\n",
      "Epoch 12/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3317 - accuracy: 0.8444 - val_loss: 0.3376 - val_accuracy: 0.8363\n",
      "Epoch 13/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3311 - accuracy: 0.8453 - val_loss: 0.3378 - val_accuracy: 0.8384\n",
      "Epoch 14/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3307 - accuracy: 0.8458 - val_loss: 0.3366 - val_accuracy: 0.8396\n",
      "Epoch 15/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3301 - accuracy: 0.8459 - val_loss: 0.3386 - val_accuracy: 0.8396\n",
      "Epoch 16/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3298 - accuracy: 0.8456 - val_loss: 0.3399 - val_accuracy: 0.8409\n",
      "Epoch 17/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3295 - accuracy: 0.8462 - val_loss: 0.3396 - val_accuracy: 0.8388\n",
      "Epoch 18/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3292 - accuracy: 0.8462 - val_loss: 0.3381 - val_accuracy: 0.8413\n",
      "Epoch 19/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3287 - accuracy: 0.8459 - val_loss: 0.3368 - val_accuracy: 0.8400\n",
      "Epoch 20/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3287 - accuracy: 0.8468 - val_loss: 0.3381 - val_accuracy: 0.8417\n",
      "Epoch 21/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3284 - accuracy: 0.8462 - val_loss: 0.3379 - val_accuracy: 0.8413\n",
      "Epoch 22/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3282 - accuracy: 0.8470 - val_loss: 0.3378 - val_accuracy: 0.8400\n",
      "Epoch 23/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3280 - accuracy: 0.8476 - val_loss: 0.3384 - val_accuracy: 0.8359\n",
      "Epoch 24/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3277 - accuracy: 0.8466 - val_loss: 0.3365 - val_accuracy: 0.8425\n",
      "Epoch 25/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3269 - accuracy: 0.8468 - val_loss: 0.3377 - val_accuracy: 0.8400\n",
      "Epoch 26/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3273 - accuracy: 0.8462 - val_loss: 0.3370 - val_accuracy: 0.8421\n",
      "Epoch 27/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3271 - accuracy: 0.8462 - val_loss: 0.3366 - val_accuracy: 0.8425\n",
      "Epoch 28/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3263 - accuracy: 0.8473 - val_loss: 0.3375 - val_accuracy: 0.8409\n",
      "Epoch 29/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3268 - accuracy: 0.8461 - val_loss: 0.3361 - val_accuracy: 0.8429\n",
      "Epoch 30/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3262 - accuracy: 0.8473 - val_loss: 0.3381 - val_accuracy: 0.8409\n",
      "Epoch 31/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3262 - accuracy: 0.8468 - val_loss: 0.3382 - val_accuracy: 0.8400\n",
      "Epoch 32/100\n",
      "679/679 [==============================] - 2s 4ms/step - loss: 0.3262 - accuracy: 0.8458 - val_loss: 0.3376 - val_accuracy: 0.8404\n",
      "Epoch 33/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3260 - accuracy: 0.8461 - val_loss: 0.3357 - val_accuracy: 0.8421\n",
      "Epoch 34/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3258 - accuracy: 0.8466 - val_loss: 0.3382 - val_accuracy: 0.8442\n",
      "Epoch 35/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3256 - accuracy: 0.8470 - val_loss: 0.3363 - val_accuracy: 0.8409\n",
      "Epoch 36/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3256 - accuracy: 0.8464 - val_loss: 0.3367 - val_accuracy: 0.8392\n",
      "Epoch 37/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3255 - accuracy: 0.8461 - val_loss: 0.3364 - val_accuracy: 0.8413\n",
      "Epoch 38/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3251 - accuracy: 0.8473 - val_loss: 0.3374 - val_accuracy: 0.8417\n",
      "Epoch 39/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3252 - accuracy: 0.8473 - val_loss: 0.3365 - val_accuracy: 0.8392\n",
      "Epoch 40/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3252 - accuracy: 0.8470 - val_loss: 0.3359 - val_accuracy: 0.8417\n",
      "Epoch 41/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3251 - accuracy: 0.8471 - val_loss: 0.3382 - val_accuracy: 0.8425\n",
      "Epoch 42/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3249 - accuracy: 0.8467 - val_loss: 0.3352 - val_accuracy: 0.8413\n",
      "Epoch 43/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3248 - accuracy: 0.8486 - val_loss: 0.3353 - val_accuracy: 0.8396\n",
      "Epoch 44/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3246 - accuracy: 0.8476 - val_loss: 0.3363 - val_accuracy: 0.8433\n",
      "Epoch 45/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3246 - accuracy: 0.8481 - val_loss: 0.3343 - val_accuracy: 0.8388\n",
      "Epoch 46/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3245 - accuracy: 0.8473 - val_loss: 0.3357 - val_accuracy: 0.8462\n",
      "Epoch 47/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3244 - accuracy: 0.8462 - val_loss: 0.3343 - val_accuracy: 0.8404\n",
      "Epoch 48/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3243 - accuracy: 0.8479 - val_loss: 0.3357 - val_accuracy: 0.8438\n",
      "Epoch 49/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3246 - accuracy: 0.8484 - val_loss: 0.3344 - val_accuracy: 0.8384\n",
      "Epoch 50/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3241 - accuracy: 0.8474 - val_loss: 0.3344 - val_accuracy: 0.8404\n",
      "Epoch 51/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3243 - accuracy: 0.8479 - val_loss: 0.3349 - val_accuracy: 0.8404\n",
      "Epoch 52/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3238 - accuracy: 0.8484 - val_loss: 0.3348 - val_accuracy: 0.8400\n",
      "Epoch 53/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3239 - accuracy: 0.8479 - val_loss: 0.3342 - val_accuracy: 0.8380\n",
      "Epoch 54/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3237 - accuracy: 0.8478 - val_loss: 0.3343 - val_accuracy: 0.8400\n",
      "Epoch 55/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3238 - accuracy: 0.8481 - val_loss: 0.3345 - val_accuracy: 0.8400\n",
      "Epoch 56/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3239 - accuracy: 0.8482 - val_loss: 0.3343 - val_accuracy: 0.8421\n",
      "Epoch 57/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3239 - accuracy: 0.8474 - val_loss: 0.3356 - val_accuracy: 0.8421\n",
      "Epoch 58/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3237 - accuracy: 0.8479 - val_loss: 0.3354 - val_accuracy: 0.8404\n",
      "Epoch 59/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3231 - accuracy: 0.8485 - val_loss: 0.3364 - val_accuracy: 0.8413\n",
      "Epoch 60/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3237 - accuracy: 0.8480 - val_loss: 0.3349 - val_accuracy: 0.8413\n",
      "Epoch 61/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3236 - accuracy: 0.8473 - val_loss: 0.3344 - val_accuracy: 0.8375\n",
      "Epoch 62/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3232 - accuracy: 0.8491 - val_loss: 0.3343 - val_accuracy: 0.8429\n",
      "Epoch 63/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3232 - accuracy: 0.8489 - val_loss: 0.3335 - val_accuracy: 0.8438\n",
      "Epoch 64/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3232 - accuracy: 0.8473 - val_loss: 0.3350 - val_accuracy: 0.8438\n",
      "Epoch 65/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3228 - accuracy: 0.8479 - val_loss: 0.3347 - val_accuracy: 0.8371\n",
      "Epoch 66/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3231 - accuracy: 0.8476 - val_loss: 0.3349 - val_accuracy: 0.8380\n",
      "Epoch 67/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3230 - accuracy: 0.8482 - val_loss: 0.3338 - val_accuracy: 0.8375\n",
      "Epoch 68/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3227 - accuracy: 0.8480 - val_loss: 0.3362 - val_accuracy: 0.8421\n",
      "Epoch 69/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3232 - accuracy: 0.8489 - val_loss: 0.3335 - val_accuracy: 0.8409\n",
      "Epoch 70/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3230 - accuracy: 0.8487 - val_loss: 0.3330 - val_accuracy: 0.8413\n",
      "Epoch 71/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3228 - accuracy: 0.8478 - val_loss: 0.3352 - val_accuracy: 0.8425\n",
      "Epoch 72/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3231 - accuracy: 0.8481 - val_loss: 0.3334 - val_accuracy: 0.8404\n",
      "Epoch 73/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3227 - accuracy: 0.8485 - val_loss: 0.3328 - val_accuracy: 0.8404\n",
      "Epoch 74/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3228 - accuracy: 0.8477 - val_loss: 0.3331 - val_accuracy: 0.8363\n",
      "Epoch 75/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3225 - accuracy: 0.8490 - val_loss: 0.3343 - val_accuracy: 0.8421\n",
      "Epoch 76/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3229 - accuracy: 0.8485 - val_loss: 0.3335 - val_accuracy: 0.8375\n",
      "Epoch 77/100\n",
      "679/679 [==============================] - 2s 4ms/step - loss: 0.3226 - accuracy: 0.8492 - val_loss: 0.3340 - val_accuracy: 0.8446\n",
      "Epoch 78/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3225 - accuracy: 0.8498 - val_loss: 0.3326 - val_accuracy: 0.8446\n",
      "Epoch 79/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3226 - accuracy: 0.8493 - val_loss: 0.3331 - val_accuracy: 0.8417\n",
      "Epoch 80/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3221 - accuracy: 0.8491 - val_loss: 0.3346 - val_accuracy: 0.8454\n",
      "Epoch 81/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3226 - accuracy: 0.8477 - val_loss: 0.3324 - val_accuracy: 0.8429\n",
      "Epoch 82/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3224 - accuracy: 0.8486 - val_loss: 0.3331 - val_accuracy: 0.8421\n",
      "Epoch 83/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3226 - accuracy: 0.8483 - val_loss: 0.3332 - val_accuracy: 0.8413\n",
      "Epoch 84/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3221 - accuracy: 0.8494 - val_loss: 0.3338 - val_accuracy: 0.8409\n",
      "Epoch 85/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3218 - accuracy: 0.8494 - val_loss: 0.3312 - val_accuracy: 0.8438\n",
      "Epoch 86/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3221 - accuracy: 0.8492 - val_loss: 0.3320 - val_accuracy: 0.8413\n",
      "Epoch 87/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3221 - accuracy: 0.8488 - val_loss: 0.3322 - val_accuracy: 0.8404\n",
      "Epoch 88/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3219 - accuracy: 0.8486 - val_loss: 0.3322 - val_accuracy: 0.8404\n",
      "Epoch 89/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3218 - accuracy: 0.8491 - val_loss: 0.3313 - val_accuracy: 0.8417\n",
      "Epoch 90/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3222 - accuracy: 0.8490 - val_loss: 0.3315 - val_accuracy: 0.8388\n",
      "Epoch 91/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3220 - accuracy: 0.8488 - val_loss: 0.3319 - val_accuracy: 0.8404\n",
      "Epoch 92/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3221 - accuracy: 0.8507 - val_loss: 0.3316 - val_accuracy: 0.8404\n",
      "Epoch 93/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3218 - accuracy: 0.8491 - val_loss: 0.3315 - val_accuracy: 0.8384\n",
      "Epoch 94/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3214 - accuracy: 0.8503 - val_loss: 0.3324 - val_accuracy: 0.8400\n",
      "Epoch 95/100\n",
      "679/679 [==============================] - 2s 4ms/step - loss: 0.3214 - accuracy: 0.8498 - val_loss: 0.3330 - val_accuracy: 0.8438\n",
      "Epoch 96/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3218 - accuracy: 0.8492 - val_loss: 0.3309 - val_accuracy: 0.8396\n",
      "Epoch 97/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3214 - accuracy: 0.8489 - val_loss: 0.3320 - val_accuracy: 0.8409\n",
      "Epoch 98/100\n",
      "679/679 [==============================] - 2s 4ms/step - loss: 0.3214 - accuracy: 0.8498 - val_loss: 0.3318 - val_accuracy: 0.8396\n",
      "Epoch 99/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3215 - accuracy: 0.8495 - val_loss: 0.3317 - val_accuracy: 0.8371\n",
      "Epoch 100/100\n",
      "679/679 [==============================] - 2s 4ms/step - loss: 0.3212 - accuracy: 0.8496 - val_loss: 0.3308 - val_accuracy: 0.8400\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.3335 - accuracy: 0.8450\n",
      "Evaluation Results: [0.3334612250328064, 0.8450190424919128]\n"
     ]
    }
   ],
   "source": [
    "# Build the ANN model\n",
    "ann_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(units=8, activation='relu', input_shape=(x_train_StandardScaled.shape[1],)),\n",
    "    tf.keras.layers.Dense(units=8, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "ann_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = ann_model.fit(x_train_StandardScaled, y_train, batch_size=32, epochs=100, validation_split=0.1)\n",
    "\n",
    "# Evaluate the model on test data\n",
    "eval_results = ann_model.evaluate(x_test_StandardScaled, y_test)\n",
    "print(\"Evaluation Results:\", eval_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "679/679 [==============================] - 4s 3ms/step - loss: 0.4718 - accuracy: 0.7818 - val_loss: 0.3862 - val_accuracy: 0.8214\n",
      "Epoch 2/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3707 - accuracy: 0.8302 - val_loss: 0.3594 - val_accuracy: 0.8251\n",
      "Epoch 3/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3510 - accuracy: 0.8355 - val_loss: 0.3477 - val_accuracy: 0.8268\n",
      "Epoch 4/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3399 - accuracy: 0.8412 - val_loss: 0.3435 - val_accuracy: 0.8297\n",
      "Epoch 5/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3358 - accuracy: 0.8438 - val_loss: 0.3410 - val_accuracy: 0.8317\n",
      "Epoch 6/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3332 - accuracy: 0.8446 - val_loss: 0.3398 - val_accuracy: 0.8313\n",
      "Epoch 7/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3322 - accuracy: 0.8448 - val_loss: 0.3394 - val_accuracy: 0.8342\n",
      "Epoch 8/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3310 - accuracy: 0.8467 - val_loss: 0.3398 - val_accuracy: 0.8351\n",
      "Epoch 9/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3300 - accuracy: 0.8466 - val_loss: 0.3397 - val_accuracy: 0.8351\n",
      "Epoch 10/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3297 - accuracy: 0.8475 - val_loss: 0.3379 - val_accuracy: 0.8375\n",
      "Epoch 11/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3287 - accuracy: 0.8471 - val_loss: 0.3377 - val_accuracy: 0.8351\n",
      "Epoch 12/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3287 - accuracy: 0.8481 - val_loss: 0.3381 - val_accuracy: 0.8338\n",
      "Epoch 13/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3283 - accuracy: 0.8488 - val_loss: 0.3367 - val_accuracy: 0.8359\n",
      "Epoch 14/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3275 - accuracy: 0.8474 - val_loss: 0.3381 - val_accuracy: 0.8351\n",
      "Epoch 15/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3273 - accuracy: 0.8481 - val_loss: 0.3369 - val_accuracy: 0.8363\n",
      "Epoch 16/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3267 - accuracy: 0.8484 - val_loss: 0.3367 - val_accuracy: 0.8392\n",
      "Epoch 17/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3270 - accuracy: 0.8481 - val_loss: 0.3353 - val_accuracy: 0.8359\n",
      "Epoch 18/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3265 - accuracy: 0.8484 - val_loss: 0.3351 - val_accuracy: 0.8400\n",
      "Epoch 19/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3258 - accuracy: 0.8482 - val_loss: 0.3378 - val_accuracy: 0.8363\n",
      "Epoch 20/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3260 - accuracy: 0.8478 - val_loss: 0.3355 - val_accuracy: 0.8388\n",
      "Epoch 21/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3254 - accuracy: 0.8488 - val_loss: 0.3349 - val_accuracy: 0.8384\n",
      "Epoch 22/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3254 - accuracy: 0.8474 - val_loss: 0.3340 - val_accuracy: 0.8429\n",
      "Epoch 23/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3251 - accuracy: 0.8483 - val_loss: 0.3337 - val_accuracy: 0.8380\n",
      "Epoch 24/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3249 - accuracy: 0.8477 - val_loss: 0.3338 - val_accuracy: 0.8421\n",
      "Epoch 25/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3245 - accuracy: 0.8490 - val_loss: 0.3330 - val_accuracy: 0.8433\n",
      "Epoch 26/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3243 - accuracy: 0.8482 - val_loss: 0.3330 - val_accuracy: 0.8442\n",
      "Epoch 27/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3240 - accuracy: 0.8484 - val_loss: 0.3326 - val_accuracy: 0.8409\n",
      "Epoch 28/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3240 - accuracy: 0.8493 - val_loss: 0.3315 - val_accuracy: 0.8409\n",
      "Epoch 29/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3237 - accuracy: 0.8495 - val_loss: 0.3314 - val_accuracy: 0.8429\n",
      "Epoch 30/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3233 - accuracy: 0.8496 - val_loss: 0.3322 - val_accuracy: 0.8396\n",
      "Epoch 31/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3232 - accuracy: 0.8496 - val_loss: 0.3321 - val_accuracy: 0.8438\n",
      "Epoch 32/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3229 - accuracy: 0.8486 - val_loss: 0.3311 - val_accuracy: 0.8442\n",
      "Epoch 33/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3227 - accuracy: 0.8484 - val_loss: 0.3308 - val_accuracy: 0.8483\n",
      "Epoch 34/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3224 - accuracy: 0.8492 - val_loss: 0.3315 - val_accuracy: 0.8458\n",
      "Epoch 35/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3222 - accuracy: 0.8497 - val_loss: 0.3315 - val_accuracy: 0.8438\n",
      "Epoch 36/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3222 - accuracy: 0.8503 - val_loss: 0.3312 - val_accuracy: 0.8442\n",
      "Epoch 37/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3220 - accuracy: 0.8498 - val_loss: 0.3306 - val_accuracy: 0.8438\n",
      "Epoch 38/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3219 - accuracy: 0.8502 - val_loss: 0.3325 - val_accuracy: 0.8425\n",
      "Epoch 39/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3218 - accuracy: 0.8502 - val_loss: 0.3305 - val_accuracy: 0.8454\n",
      "Epoch 40/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3215 - accuracy: 0.8507 - val_loss: 0.3294 - val_accuracy: 0.8467\n",
      "Epoch 41/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3212 - accuracy: 0.8500 - val_loss: 0.3302 - val_accuracy: 0.8442\n",
      "Epoch 42/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3212 - accuracy: 0.8492 - val_loss: 0.3296 - val_accuracy: 0.8496\n",
      "Epoch 43/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3213 - accuracy: 0.8512 - val_loss: 0.3303 - val_accuracy: 0.8446\n",
      "Epoch 44/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3206 - accuracy: 0.8514 - val_loss: 0.3289 - val_accuracy: 0.8454\n",
      "Epoch 45/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3206 - accuracy: 0.8506 - val_loss: 0.3298 - val_accuracy: 0.8450\n",
      "Epoch 46/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3204 - accuracy: 0.8507 - val_loss: 0.3297 - val_accuracy: 0.8516\n",
      "Epoch 47/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3204 - accuracy: 0.8497 - val_loss: 0.3313 - val_accuracy: 0.8450\n",
      "Epoch 48/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3198 - accuracy: 0.8519 - val_loss: 0.3346 - val_accuracy: 0.8425\n",
      "Epoch 49/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3205 - accuracy: 0.8520 - val_loss: 0.3294 - val_accuracy: 0.8454\n",
      "Epoch 50/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3201 - accuracy: 0.8509 - val_loss: 0.3310 - val_accuracy: 0.8429\n",
      "Epoch 51/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3196 - accuracy: 0.8510 - val_loss: 0.3297 - val_accuracy: 0.8479\n",
      "Epoch 52/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3196 - accuracy: 0.8505 - val_loss: 0.3299 - val_accuracy: 0.8462\n",
      "Epoch 53/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3193 - accuracy: 0.8518 - val_loss: 0.3309 - val_accuracy: 0.8475\n",
      "Epoch 54/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3192 - accuracy: 0.8518 - val_loss: 0.3302 - val_accuracy: 0.8438\n",
      "Epoch 55/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3192 - accuracy: 0.8517 - val_loss: 0.3294 - val_accuracy: 0.8504\n",
      "Epoch 56/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3191 - accuracy: 0.8512 - val_loss: 0.3301 - val_accuracy: 0.8458\n",
      "Epoch 57/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3189 - accuracy: 0.8516 - val_loss: 0.3303 - val_accuracy: 0.8479\n",
      "Epoch 58/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3187 - accuracy: 0.8514 - val_loss: 0.3317 - val_accuracy: 0.8438\n",
      "Epoch 59/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3189 - accuracy: 0.8521 - val_loss: 0.3308 - val_accuracy: 0.8454\n",
      "Epoch 60/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3185 - accuracy: 0.8520 - val_loss: 0.3303 - val_accuracy: 0.8467\n",
      "Epoch 61/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3186 - accuracy: 0.8514 - val_loss: 0.3301 - val_accuracy: 0.8462\n",
      "Epoch 62/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3187 - accuracy: 0.8519 - val_loss: 0.3309 - val_accuracy: 0.8475\n",
      "Epoch 63/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3183 - accuracy: 0.8510 - val_loss: 0.3295 - val_accuracy: 0.8492\n",
      "Epoch 64/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3182 - accuracy: 0.8517 - val_loss: 0.3310 - val_accuracy: 0.8467\n",
      "Epoch 65/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3184 - accuracy: 0.8520 - val_loss: 0.3311 - val_accuracy: 0.8467\n",
      "Epoch 66/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3180 - accuracy: 0.8521 - val_loss: 0.3309 - val_accuracy: 0.8467\n",
      "Epoch 67/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3183 - accuracy: 0.8520 - val_loss: 0.3325 - val_accuracy: 0.8433\n",
      "Epoch 68/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3182 - accuracy: 0.8525 - val_loss: 0.3331 - val_accuracy: 0.8458\n",
      "Epoch 69/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3182 - accuracy: 0.8523 - val_loss: 0.3302 - val_accuracy: 0.8458\n",
      "Epoch 70/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3182 - accuracy: 0.8525 - val_loss: 0.3310 - val_accuracy: 0.8458\n",
      "Epoch 71/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3180 - accuracy: 0.8517 - val_loss: 0.3310 - val_accuracy: 0.8500\n",
      "Epoch 72/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3179 - accuracy: 0.8523 - val_loss: 0.3312 - val_accuracy: 0.8483\n",
      "Epoch 73/100\n",
      "679/679 [==============================] - 3s 4ms/step - loss: 0.3179 - accuracy: 0.8524 - val_loss: 0.3314 - val_accuracy: 0.8462\n",
      "Epoch 74/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3175 - accuracy: 0.8527 - val_loss: 0.3301 - val_accuracy: 0.8450\n",
      "Epoch 75/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3177 - accuracy: 0.8507 - val_loss: 0.3305 - val_accuracy: 0.8479\n",
      "Epoch 76/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3177 - accuracy: 0.8520 - val_loss: 0.3313 - val_accuracy: 0.8471\n",
      "Epoch 77/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3176 - accuracy: 0.8530 - val_loss: 0.3310 - val_accuracy: 0.8442\n",
      "Epoch 78/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3178 - accuracy: 0.8508 - val_loss: 0.3322 - val_accuracy: 0.8458\n",
      "Epoch 79/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3179 - accuracy: 0.8503 - val_loss: 0.3317 - val_accuracy: 0.8433\n",
      "Epoch 80/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3178 - accuracy: 0.8522 - val_loss: 0.3308 - val_accuracy: 0.8458\n",
      "Epoch 81/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3173 - accuracy: 0.8526 - val_loss: 0.3304 - val_accuracy: 0.8458\n",
      "Epoch 82/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3175 - accuracy: 0.8518 - val_loss: 0.3328 - val_accuracy: 0.8400\n",
      "Epoch 83/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3178 - accuracy: 0.8535 - val_loss: 0.3301 - val_accuracy: 0.8475\n",
      "Epoch 84/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3176 - accuracy: 0.8523 - val_loss: 0.3299 - val_accuracy: 0.8467\n",
      "Epoch 85/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3174 - accuracy: 0.8520 - val_loss: 0.3310 - val_accuracy: 0.8504\n",
      "Epoch 86/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3176 - accuracy: 0.8524 - val_loss: 0.3288 - val_accuracy: 0.8467\n",
      "Epoch 87/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3171 - accuracy: 0.8528 - val_loss: 0.3303 - val_accuracy: 0.8475\n",
      "Epoch 88/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3175 - accuracy: 0.8528 - val_loss: 0.3303 - val_accuracy: 0.8492\n",
      "Epoch 89/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3174 - accuracy: 0.8515 - val_loss: 0.3292 - val_accuracy: 0.8512\n",
      "Epoch 90/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3171 - accuracy: 0.8521 - val_loss: 0.3298 - val_accuracy: 0.8467\n",
      "Epoch 91/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3174 - accuracy: 0.8530 - val_loss: 0.3288 - val_accuracy: 0.8487\n",
      "Epoch 92/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3170 - accuracy: 0.8532 - val_loss: 0.3305 - val_accuracy: 0.8454\n",
      "Epoch 93/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3174 - accuracy: 0.8526 - val_loss: 0.3303 - val_accuracy: 0.8487\n",
      "Epoch 94/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3173 - accuracy: 0.8529 - val_loss: 0.3292 - val_accuracy: 0.8454\n",
      "Epoch 95/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3170 - accuracy: 0.8520 - val_loss: 0.3317 - val_accuracy: 0.8442\n",
      "Epoch 96/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3171 - accuracy: 0.8524 - val_loss: 0.3305 - val_accuracy: 0.8471\n",
      "Epoch 97/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3171 - accuracy: 0.8525 - val_loss: 0.3305 - val_accuracy: 0.8475\n",
      "Epoch 98/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3173 - accuracy: 0.8532 - val_loss: 0.3291 - val_accuracy: 0.8492\n",
      "Epoch 99/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3169 - accuracy: 0.8528 - val_loss: 0.3313 - val_accuracy: 0.8458\n",
      "Epoch 100/100\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.3169 - accuracy: 0.8525 - val_loss: 0.3302 - val_accuracy: 0.8500\n",
      "189/189 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8455163268688878\n",
      "Recall: 0.5824468085106383\n",
      "Precision: 0.7423728813559322\n",
      "F1-score: 0.6527570789865872\n",
      "189/189 [==============================] - 0s 2ms/step\n",
      "AUC: 0.9014796195205367\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_curve, auc, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Perform Standard Scaling if not already done\n",
    "scaler = StandardScaler()\n",
    "x_train_StandardScaled = scaler.fit_transform(x_train)\n",
    "x_test_StandardScaled = scaler.transform(x_test)\n",
    "\n",
    "# Build the ANN model\n",
    "ann_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(units=8, activation='relu', input_shape=(x_train_StandardScaled.shape[1],)),\n",
    "    tf.keras.layers.Dense(units=8, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "ann_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = ann_model.fit(x_train_StandardScaled, y_train, batch_size=32, epochs=100, validation_split=0.1)\n",
    "\n",
    "# Predict on the test set using the trained ANN model\n",
    "y_pred = (ann_model.predict(x_test_StandardScaled) > 0.5).astype(\"int32\")\n",
    "\n",
    "# Create the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Positive\", \"Negative\"])  # Replace with your class labels\n",
    "disp.plot(cmap=plt.cm.OrRd)\n",
    "plt.xlabel(\"Predicted labels\")\n",
    "plt.ylabel(\"Actual labels\")\n",
    "plt.show()\n",
    "\n",
    "# Calculate and print the performance metrics\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred))  # By default, pos_label=1 for binary classification\n",
    "print(\"Precision:\", precision_score(y_test, y_pred))  # By default, pos_label=1 for binary classification\n",
    "print(\"F1-score:\", f1_score(y_test, y_pred))  # By default, pos_label=1 for binary classification\n",
    "\n",
    "# Plotting the ROC curve and calculating the AUC\n",
    "y_pred_prob = ann_model.predict(x_test_StandardScaled)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(\"AUC:\", roc_auc)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.plot(fpr, tpr, color='green')\n",
    "plt.title('ROC Curve')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate (Recall)')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
